---
title: "Comparison of Bayesian MCPMod and MCPMod"
format: 
  html:
    fig-height: 3.5
    self-contained: true
    toc: true
    number-sections: true
    code-summary: setup
    code-fold: true
    message: false
    warning: false
vignette: >
  %\VignetteIndexEntry{Comparison of Bayesian MCPMod and MCPMod}
  %\VignetteEngine{quarto::html}
  %\VignetteEncoding{UTF-8}
---

```{r}
#| code-summary: setup
#| code-fold: true
#| message: false
#| warning: false

library(BayesianMCPMod)
library(DoseFinding)
library(MCPModPack)

library(tidyr)
library(kableExtra)

# library(reactable)

# library(clinDR)

# library(tibble)
# library(data.table)

library(doFuture)

# func_sim <- function(models, sim_models, sim_parameters){
# 
#   sim_result = MCPModSimulation(endpoint_type = "Normal",
#                                 models = models,
#                                 alpha = alpha,
#                                 direction = "increasing",
#                                 model_selection = "aveAIC",
#                                 Delta = 0.1,
#                                 sim_models = sim_models,
#                                 sim_parameters = sim_parameters)
# }
```

# Introduction

This vignette demonstrates the application of the {BayesianMCPMod} package for sample size calculations and the comparison with the {MCPModPack} package.
Bayesian MCPMod is set up in a way that it  mimics the results (and operating characteristics) of the frequentist MCPMod for non-informative priors.
This characteristic is illustrated in the following sections focusing on the trial planning. 

The following dose-finding scenario is considered to compare Bayesian MCPMod and MCPModPack success probabilities:

-   four dose levels plus placebo (0 mg, 1 mg, 2 mg, 4 mg, 8 mg)

-   total sample size of N = 200 with an equal allocation ratio for each dose group, i.e., 40 per group

-   standard deviation of 0.4 for every dose group

-   alpha level of 5%

Building on this scenario, the following varying effects are used:

-   expected effect for maximum dose of (0.0001, 0.05, 0.1, 0.2, 0.3, 0.5)

The value of 0.0001 was chosen instead of 0 due to technical reasons.
This case should mimic the null scenario (where we expect a success probability close to the alpha level).

For each of these simulation cases, 10000 simulation runs are performed. 
Given the number of simulations and applying the law of large numbers, the difference in success probabilities should be in the range of 1%-3%.

```{r}
# Scenario parameters
doses_sim     <- c(0, 1, 2, 4, 8) 
n_sample      <- c(40, 40, 40, 40, 40)
sd_sim        <- 0.4

max_dose      <- max(doses_sim)    
plc_eff_guess <- 0    

alpha         <- 0.05

exp_eff_fix   <- 0.2 
exp_eff       <- c(0.0001, 0.05, 0.1, 0.2, 0.3, 0.5)

# Simulation parameters
n_sim         <- 100 # to be up-scaled to 10000

set.seed(7015)
plan(multisession)
```

In the following, the candidate models are specified and plotted.

```{r}
# Candidate Models
emax_guess     <- guesst(d = doses_sim[2], p = 0.6, "emax") 
exp_guess      <- guesst(d = doses_sim[2], p = 0.05, model = "exponential", Maxd = max_dose)
logit_guess    <- guesst(d = c(doses_sim[2], doses_sim[3]), p = c(0.1, 0.9), "logistic", Maxd = max_dose) 
sig_emax_guess <- guesst(d = c(doses_sim[2], doses_sim[3]), p = c(0.15, 0.75), model = "sigEmax") 

scenario_models <- Mods(linear      = NULL,
                        exponential = exp_guess,
                        emax        = emax_guess,
                        logistic    = logit_guess,
                        sigEmax     = sig_emax_guess,
                        doses       = doses_sim,
                        placEff     = plc_eff_guess,
                        maxEff      = exp_eff_fix,
                        direction   = "increasing")

plot(scenario_models, main = "Monotonic Scenario")
```

# Varying the Expected Effect for Maximum Dose

## MCPModPack Implementation

```{r warning = FALSE}
# Simulation parameters
sim_parameters <- list(n            = n_sample,
                       doses        = doses_sim,
                       dropout_rate = 0.0,
                       go_threshold = 0.1,
                       nsims        = n_sim)

# Candidate dose - response models
models_MCPModPack = list(linear      = NA,
                         exponential = 4.447149,
                         emax        = 0.6666667,
                         logistic    = c(1.5, 0.2275598),
                         sigemax     = c(1.528629, 4.087463))

# Assumed dose - response models (models will be added in loop)
sim_models_stomp <- list(max_effect     = exp_eff,
                         sd             = rep(sd_sim, length(doses_sim)),
                         placebo_effect = plc_eff_guess)

# Parallelization across assumed dose - response models
powers_MCPModPack <- foreach(
  k = seq_along(models_MCPModPack),
  .combine = cbind, 
  .options.future = list(seed = TRUE)) %dofuture% {
    
    sim_model_k <- c(models_MCPModPack[k], sim_models_stomp)
    
    MCPModSimulation(endpoint_type   = "Normal",
                     models          = models_MCPModPack,
                     alpha           = alpha,
                     direction       = "increasing",
                     model_selection = "aveAIC",
                     Delta           = 0.1,
                     sim_models      = sim_model_k,
                     sim_parameters  = sim_parameters)$sim_results$power
  
  }

# Post-processing result for printing
colnames(powers_MCPModPack) <- names(models_MCPModPack)
results_MCPModPack <- cbind(max_eff = round(exp_eff, digits = 2),
                            powers_MCPModPack) %>%
  data.frame() %>%
  rename(sigEmax = sigemax) %>%
  mutate(average = rowMeans(select(., linear:sigEmax)))
```

## Bayesian MCPMod Implementation

The following simulations will be conducted utilizing the 'BayesianMCPMod' package using the same scenarios as for the frequentist evaluations.

First, a vague prior is specified for each dose group:

```{r}
prior_list_vague <- rep(list(RBesT::mixnorm(comp1 = c(w = 1, m = 0, n = 1),
                                            sigma = sd_sim, param = "mn")),
                        times = length(doses_sim))
names(prior_list_vague) <- c("Ctrl", "DG_1", "DG_2", "DG_3", "DG_4")
```

To calculate success probabilities for the different assumed dose-response models and the specified trial design we will apply the assessDesign function. 

```{r}
# Parallelization across the expected effects for maximum dose
success_rates_BayesianMCPMod <- foreach(
  k               = seq_along(exp_eff),
  .combine        = rbind, 
  .options.future = list(seed = TRUE)) %dofuture% {
    
    exp_eff_k <- exp_eff[k]
    
    models_BayesianMCPMod <- Mods(linear      = NULL,
                                  exponential = exp_guess,
                                  emax        = emax_guess,
                                  logistic    = logit_guess,
                                  sigEmax     = sig_emax_guess,
                                  doses       = doses_sim,
                                  placEff     = plc_eff_guess,
                                  maxEff      = exp_eff_k,
                                  direction   = "increasing")
       
    # Optimal contrasts
    contr <- getContr(mods         = models_BayesianMCPMod,
                      dose_levels  = doses_sim,
                      prior_list   = prior_list_vague,
                      dose_weights = rep(1, length(doses_sim)))
  
    # Perform Simulations
    sim_result <- assessDesign(n_patients     = n_sample,
                               mods           = models_BayesianMCPMod,
                               prior_list     = prior_list_vague,
                               sd             = sd_sim,
                               n_sim          = n_sim,
                               alpha_crit_val = alpha,
                               contr          = contr)
    
    
    ## diag takes the success rate of model_x in case model_x is the true model
    c(diag(do.call(rbind, lapply(sim_result, function (x) {
      
      getModelSuccesses(x$BayesianMCP)
      
    }))), average = attr(sim_result, "avgSuccessRate"))
  
  }

# Post-processing result for printing
rownames(success_rates_BayesianMCPMod) <- NULL
results_BayesianMCPMod <- data.frame(cbind(max_eff = round(exp_eff, digits = 2),
                                                 success_rates_BayesianMCPMod))
```

## Comparison

In the following, the comparisons between the success probabilities (i.e., power values for frequentist set-up) of various scenarios and different parameters are visualized.

```{r}
#table with results
kable(results_MCPModPack) %>%
  kable_classic(full_width = TRUE) %>%
    add_header_above(c("Power Results Across Different Expected Effects" = 7),
                     font_size = 15, bold = TRUE) %>%
    add_header_above(c("MCPModPack" = 7), font_size = 15, bold = TRUE)
  
kable(results_BayesianMCPMod) %>%
  kable_classic(full_width = TRUE) %>%
    add_header_above(c("Success Rates Across Different Expected Effects" = 7),
                     font_size = 15, bold = TRUE) %>%
    add_header_above(c("BayesianMCPMod" = 7), font_size = 15, bold = TRUE) 
```

The following plot shows the difference between the results from MCPModPack and BayesianMCPMod.
The results of MCPModPack are shown as a line and the difference to the result with BayesianMCPMod is presented as a bar.
The results for the different assumed true dose-response models, which were the basis for simulating the data, are shown in different colours.
As expected, the operating characteristics of BayesianMCPMod with non-informative prior match the operating characteristics of frequentist MCPMod.
```{r}

## pre-processing the data
df_plot <- rbind(results_MCPModPack %>% 
                   mutate(package_name = "MCPModPack"),
                 results_BayesianMCPMod %>% 
                   mutate(package_name = "BayesianMCPMod")) %>%
  pivot_longer(cols      = names(results_BayesianMCPMod)[-1],
               names_to  = "model_shape",
               values_to = "success_rate") %>%
  filter(model_shape != "average") %>%
  spread(key = package_name, value = success_rate)  %>%
  mutate(model_shape = as.factor(model_shape),
         max_eff     = as.factor(max_eff)) %>%
  group_by(max_eff) %>%
  mutate(offset = 0.1 * (seq_along(model_shape) - ceiling(length(model_shape) / 2)))

# Plot with short horizontal dashes for each model_shape
ggplot(df_plot, aes(x = as.numeric(max_eff) + offset, y = BayesianMCPMod, color = model_shape)) +
  geom_segment(aes(x = as.numeric(max_eff) + offset - 0.05, xend = as.numeric(max_eff) + offset + 0.05,
                   y = BayesianMCPMod, yend = BayesianMCPMod)) +
  geom_segment(aes(xend = as.numeric(max_eff) + offset, yend = MCPModPack)) +
  scale_x_continuous(breaks = unique(as.numeric(df_plot$max_eff)), labels = levels(df_plot$max_eff)) +
  labs(title    = "Comparing Power and Success Rate for Different Expected Effects for Maximum Dose",
       x        = "Expected Effect for Maximum Dose",
       y        = "Power or Success Rate",
       color    = "Assumed True Model Shapes",
       linetype = "Type",
       caption  = "Horizontal lines represent the BayesianMCPMod success rates \n and vertical lines mark the distance to the MCPModPack power.") +
  theme_minimal() + 
  theme(legend.position = "bottom")
```



# Convergence of Power Values

In the following simulations, we examine the convergence of power values for an increasing number of simulations.
We are considering the following number of simulations: 100, 500, 1000, 2500, 5000, 10000.

## Monotonic MCPModPack

```{r warning=FALSE}

sim_models_linear$max_effect   <- exp_eff_fix
sim_models_exp$max_effect      <- exp_eff_fix
sim_models_emax$max_effect     <- exp_eff_fix
sim_models_logistic$max_effect <- exp_eff_fix
sim_models_sigemax$max_effect  <- exp_eff_fix

list_models <- c(rep(list(sim_models_linear), 4),
                 rep(list(sim_models_exp), 4),
                 rep(list(sim_models_emax), 4),
                 rep(list(sim_models_logistic), 4),
                 rep(list(sim_models_sigemax), 4))

n_sim_values_list <- rep(list(10, 50, 100, 250, 500, 1000), 4)

chunks <- chunkVector(seq_along(list_models), getDoParWorkers())

results_list_nsim_MCP_monotonic <- foreach(k = chunks, .combine = c, .export = c(as.character(models_MCPModPack)))  %dorng% {
  
  lapply(k, function (i) {

  sim_parameters = list(n          = n_sample,
                      doses        = doses_sim,
                      dropout_rate = 0.0,
                      go_threshold = 0.1,
                      nsims        = n_sim_values_list[[i]])
    
    func_sim(models_MCPModPack, list_models[[i]], sim_parameters)
    
  })
  
}

```

## Monotonic BayesianMCPMod

```{r}
n_sim_values_list <- list(10, 50, 100, 250, 500, 1000)

# Initialize a list to store the results
results_list_nsim_Bay_monotonic <- list()
 
monotonic_models <- Mods(linear      = NULL,
                         exponential = exp_guess,
                         emax        = emax_guess,
                         logistic    = logit_guess,
                         sigEmax     = sig_emax_guess,
                         doses       = doses_sim,
                         placEff     = plc_eff_guess,
                         maxEff      = exp_eff_fix,
                         direction   = "increasing")

#optimal contrasts
contM <- getContr(mods         = monotonic_models,
                  dose_levels  = doses_sim,
                  prior_list   = prior_list_vague,
                  dose_weights = c(1, 1, 1, 1, 1))

chunks <- chunkVector(seq_along(n_sim_values_list), getDoParWorkers())

results_list_nsim_Bay_monotonic <- foreach(k = chunks, .combine = c, .export = c(as.character(monotonic_models), as.character(contM))) %dorng% {

  lapply(k, function (i) {


 # Simulation step
  success_probabilities_monotonic <- assessDesign(
    n_patients     = n_sample,
    mods           = monotonic_models,
    prior_list     = prior_list_vague,
    sd             = sd_sim,
    n_sim          = n_sim_values_list[[i]],
    alpha_crit_val = alpha,
    contr = contM)

  })

}

results_nsim_Bay_monotonic <- extract_success_rates_nsim(results_list_nsim_Bay_monotonic, names(monotonic_models), unlist(n_sim_values_list))

```

## Results

The following plots show the result of the convergence test of the power values for an increasing number of simulations. The difference between the success probabilities of the frequency and Bayesian simulations is shown.

```{r}
#safe results in data.table for plot
results_nsim_monotonic <- data.table(
  MCP_linear = c(results_list_nsim_MCP_monotonic[[1]]$sim_results$power,
                 results_list_nsim_MCP_monotonic[[2]]$sim_results$power,
                 results_list_nsim_MCP_monotonic[[3]]$sim_results$power,
                 results_list_nsim_MCP_monotonic[[4]]$sim_results$power,
                 results_list_nsim_MCP_monotonic[[5]]$sim_results$power,
                 results_list_nsim_MCP_monotonic[[6]]$sim_results$power),
  MCP_exp = c(results_list_nsim_MCP_monotonic[[7]]$sim_results$power,
              results_list_nsim_MCP_monotonic[[8]]$sim_results$power,
              results_list_nsim_MCP_monotonic[[9]]$sim_results$power,
              results_list_nsim_MCP_monotonic[[10]]$sim_results$power,
              results_list_nsim_MCP_monotonic[[11]]$sim_results$power,
              results_list_nsim_MCP_monotonic[[12]]$sim_results$power),
  MCP_emax = c(results_list_nsim_MCP_monotonic[[13]]$sim_results$power,
               results_list_nsim_MCP_monotonic[[14]]$sim_results$power,
               results_list_nsim_MCP_monotonic[[15]]$sim_results$power,
               results_list_nsim_MCP_monotonic[[16]]$sim_results$power,
               results_list_nsim_MCP_monotonic[[17]]$sim_results$power,
               results_list_nsim_MCP_monotonic[[18]]$sim_results$power),
  MCP_logistic = c(results_list_nsim_MCP_monotonic[[19]]$sim_results$power,
                   results_list_nsim_MCP_monotonic[[20]]$sim_results$power,
                   results_list_nsim_MCP_monotonic[[21]]$sim_results$power,
                   results_list_nsim_MCP_monotonic[[22]]$sim_results$power,
                   results_list_nsim_MCP_monotonic[[23]]$sim_results$power,
                   results_list_nsim_MCP_monotonic[[24]]$sim_results$power),
  MCP_sigemax = c(results_list_nsim_MCP_monotonic[[25]]$sim_results$power,
                  results_list_nsim_MCP_monotonic[[26]]$sim_results$power,
                  results_list_nsim_MCP_monotonic[[27]]$sim_results$power,
                  results_list_nsim_MCP_monotonic[[28]]$sim_results$power,
                  results_list_nsim_MCP_monotonic[[29]]$sim_results$power,
                  results_list_nsim_MCP_monotonic[[30]]$sim_results$power),
  Bay_linear = results_nsim_Bay_monotonic$Bay_linear,
  Bay_exp = results_nsim_Bay_monotonic$Bay_exponential,
  Bay_emax = results_nsim_Bay_monotonic$Bay_emax,
  Bay_logistic = results_nsim_Bay_monotonic$Bay_logistic,
  Bay_sigemax = results_nsim_Bay_monotonic$Bay_sigEmax)

results_nsim_diff_monotonic <- data.table(
  linear = results_nsim_monotonic$Bay_linear - results_nsim_monotonic$MCP_linear,
  exponential = results_nsim_monotonic$Bay_exp - results_nsim_monotonic$MCP_exp,
  emax = results_nsim_monotonic$Bay_emax - results_nsim_monotonic$MCP_emax,
  logistic = results_nsim_monotonic$Bay_logistic - results_nsim_monotonic$MCP_logistic,
  sigemax = results_nsim_monotonic$Bay_sigemax - results_nsim_monotonic$MCP_sigemax,
  n_sim = unlist(n_sim_values_list)
)

results_nsim_diff_monotonic <- melt(results_nsim_diff_monotonic, id.vars = "n_sim")

plot_nsim_monotonic <-  plot_power_deviation(results_nsim_diff_monotonic, results_nsim_diff_monotonic$n_sim, "nsim")
plot_nsim_monotonic
```
